/*
* https://en.wikipedia.org/wiki/Lexical_analysis
* A lexer, also known as a tokenizer, forms the first phase of a compiler
* frontend in modern processing.
* The tokenizer is responsible for dividing the input stream into individual
* tokens, identifying the token type, and passing tokens one at a time to the
* next stage of the compiler.
*/
/*********************************************************
* https://github.com/timpeskett/c-lex/blob/master/lexer.c
* This is the module that performs the file I/O and defines the C regular
* expressions.
* In theory, this module and the symtable module could be changed to build a
* lexical analyser for a different language.
*********************************************************/
